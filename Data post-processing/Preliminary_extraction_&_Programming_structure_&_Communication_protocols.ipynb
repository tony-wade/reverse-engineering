{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cwJGLL29ggPE",
        "k_GZ-1HykJn3",
        "9iK_ICKHGzuL",
        "Ce6vGFf1wIxg"
      ],
      "authorship_tag": "ABX9TyOC4zEc4Juf70WYgGPNiuJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tony-wade/Reverse-Engineering/blob/main/Data%20post-processing/Primal_extraction_%26_Programming_structure_%26_Communication_protocols.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author Information\n",
        "This code is provided by **Wade Wu**.\n",
        "\n",
        "For license information, please visit my [GitHub repository](https://github.com/tony-wade/Reverse-Engineering). Contributions and feedback are always welcome!\n"
      ],
      "metadata": {
        "id": "j74IMsRHyQ35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MCU燒錄淺談\n",
        "能重覆燒錄的分為EEPROM或Flash\n",
        "\n",
        "\n",
        "1.   Flash: 電訊號即可清寫,方便\n",
        "2.   EEPROM(非快閃): 需用強紫外線清除後才能寫入"
      ],
      "metadata": {
        "id": "JGShQgChrFyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "flah在寫入時會需要輸入一對hex code作為起始燒錄的通知,\n",
        "\n",
        "    ex. AA55, A5F1,...\n",
        "    (以instruction為準,因aa/55h在電訊號中較不易因noise而產生=少見)\n",
        "    應用上會配合特定的步驟做使用，須完全正確才會開始燒錄flash\n",
        "    反之，讀取則能隨意讀\n",
        "\n",
        "但也能用如同外部記憶體寫入的方式(MOVX)來寫，實際狀況與spec不一定完全相同\n"
      ],
      "metadata": {
        "id": "bFPW6rpjXdkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "寫入MCU的 C code會轉換成 assembly, 接著轉為.bin與.hex類檔案, 其中.hex格式如 intel hex等。能表示燒錄進 mcu的位置,以 code運行次序作為排列基準。\n",
        "\n",
        ".\n",
        "\n",
        "燒錄目的是將 assembly寫入 flash, 但寫入方式因設計而異，全看 bootloader(程式)怎麼設計。\n",
        "\n",
        "簡單的如 8K41直接在通訊中某段開始自0000H按序寫入。\n",
        "\n",
        "但也有可能以特殊的通訊/加密方式 encoded, 如各段結尾可能有CRC byte(s)做確認等，再轉換為原本的 assembly。"
      ],
      "metadata": {
        "id": "uVc-VYkAEDpR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**注意各logic analyser對於 start-stop在輸出資料的呈現**"
      ],
      "metadata": {
        "id": "b1LFYtsOvjUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "今mcu為二線燒錄: clock, data (即不含gnd, vcc), 且訊號起始條件為clock-low/data-high。經蕭特基+電阻線路確認data為雙端傳輸。\n",
        "\n",
        "其中，傳送端似乎固定以 0110b (B0)做指示, 0111b (B8)三組傳資料+兩組出現特定值(EA,EB, 6A,6B), 與接收端以 0011b (98) 回傳和(B8)相同的三組傳資料。\n",
        "\n",
        "功耗約 41~74 mW"
      ],
      "metadata": {
        "id": "PakfborZ6Vot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 部分8051系列MCU的燒錄準則"
      ],
      "metadata": {
        "id": "cwJGLL29ggPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "UART為獨立單向線路做溝通且以事先設定之Baud Rate為通訊速度, 不含clock (或是傳a,5,f,0這類來做auto baud rate)\n",
        "\n",
        "JTAG為4線燒錄; SPI則有3 or 4線\n",
        "\n",
        "以上能藉由自定義hand shaking/reset方式來將燒錄時的線路降至2, ex. SWJ-DP(STM)"
      ],
      "metadata": {
        "id": "P_mD4yTyCSa4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Silicon Labs: AN127 - C2 Interface\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# LSB first\n",
        "注意: 各指令間的stop-start波型會被分析儀判定為0b01/0b00(可由手冊及分析儀資料推知)，\n",
        "    且data write後與data read等待回傳時會有wait插入, 會是00...01\n",
        "\n",
        "```\n",
        "```  \n",
        "                        block write機器碼:\n",
        "\n",
        "0.   純CLK操作(略)\n",
        "1.   addr write: 0b11 0x02  \n",
        "              (FPCTL register)\n",
        "2.   data write: 0b01 0b00 0x02    <->    10 00 01000000 (LSB first)\n",
        "           ''   ''  0x04\n",
        "           ''   ''  0x01\n",
        "           (ins.)(len.)(flash write enable)\n",
        "\n",
        "3.   addr write: 0b11 0x__\n",
        "              (FPDAT register,因型號而異,pass Flash commands, addresses, and data during C2 Flash accesses)\n",
        "4.   data write: 0b01 0b00 0x07\n",
        "           (ins.)(len.)(PI:block write, block size=code length <= 256, 1 block=多個page)\n",
        "                  (other ins.: page read/erase, device erase)\n",
        "\n",
        "\n",
        "InBusy:\n",
        "5.   addr read: 0b10 \"mcu 回傳 8 bits\", 重複確認直到倒數第二位=0\n",
        "OutReady:\n",
        "6.   addr read: 0b10 \"mcu 回傳 8 bits\", 重複確認直到末位=1 (aka. 0x80, FPDAT is ready)\n",
        "Ok/Success:\n",
        "7.   data read: 0b00 0b00 \"回傳1byte\", 直到=0x0D\n",
        "           (ins.)(len.)\n",
        "\n",
        "Set write-in addr.:\n",
        "8.   data write: 0b01 0b00 0x__(first code addr.高位)\n",
        "9.   InBusy\n",
        "10.   data write: 0b01 0b00 0x__(first code addr.低位)\n",
        "11.   InBusy\n",
        "\n",
        "Set write-in len.:\n",
        "12.   data write: 0b01 0b00 0x__(=code length, 00=1 byte)\n",
        "13.   InBusy\n",
        "\n",
        "Write-in in byte:\n",
        "14.   data write: 0b01 0b00 0x__(=assembly code)\n",
        "15.   InBusy\n",
        "     (重複14.15逐byte寫入直到寫完)\n",
        "\n",
        "Finish\n",
        "16.   OutReady + step 7.\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "              write to SFR\n",
        "\n",
        "without paging:\n",
        "0.  addr read   0x__(SFR location)\n",
        "1.  data write  0x__(code)\n",
        "\n",
        "paging:\n",
        "0.  block write step1.\n",
        "1.  data write 0x0A (direct write cmd)\n",
        "2.  InBusy\n",
        "3.  OutReady & ok\n",
        "\n",
        "4.  data write  0x__(SFR location)\n",
        "5.  InBusy\n",
        "6.  data write  0x01\n",
        "7.  InBusy\n",
        "\n",
        "8.  data write  0x__(new SFR value)\n",
        "9.  InBusy\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3YyiC9grc_GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   SMBus:\n",
        "\n",
        "   屬於類I2C protocol的通訊方式，Silicon Labs下的晶片能以此做二線通信。 Flash燒錄上則是開啟特定register位置後使用MOVX指令做寫入，但不同晶片間開啟差異大。\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# MSB first\n",
        "Ack是由接收端發送的訊號\n",
        "\n",
        "R/W : S |　slave addr　｜ R/W | Ack | Data | Ack | P     or\n",
        " bits: 1     8      1    1    8   1    1\n",
        "\n",
        "                 ...    | Data | Ack | Data | Ack | ....\n"
      ],
      "metadata": {
        "id": "Tr_KfRcmKGUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Atmel(microchip)-AT89LP:SPI\n",
        "\n",
        " By CTO, 能藉由自定義reset方式來將燒錄時的線路降至2 (SDA,SCL)。\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# MSB first\n",
        "ps. 少數型號不須'55',同時不支援 Write with auto erase\n",
        "\n",
        "Program enable: AA 55 AC 53 '53'\n",
        "                 由slave回傳\n",
        "\n",
        "Write code page:  AA 55 50  addr(h) addr(l) data_bytes\n",
        "            _ _ '70'  _    _     _\n",
        "              with auto erase\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "zCr6AXdOldNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   TK18 - I2C\n",
        "\n",
        "   無詳細communication datasheet, 直接與燒錄訊號,反組譯資料做比對\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "與燒錄按鍵時刻做比對，燒錄起始為5a a5\n",
        "\n",
        "flash register addr.應是 0x40, program instruction write 則為 0x50\n",
        "(I2C:7 bits addr.+ write = A0 ACK 05 ACK)\n",
        "\n",
        "僅看到page write,一次寫 1 page共 128 bytes, 各段後方會帶一段其他資料\n",
        "\n",
        "訊號顯示是 write[0x40]: 00 F8 0A\n",
        "      stop 長間隔 start = 0b010\n",
        "      write[0x40]: 05 datas...\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "td5Gio6BpxOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### eMMC5.1 通訊格式\n",
        "此格式為統一規範!"
      ],
      "metadata": {
        "id": "k_GZ-1HykJn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "共有11個 input pin: CLK, CMD(command & response), DataStrobe( high speed時的CLK), DATA[0] ~ DATA[7]\n",
        "\n",
        "host一次只能與1 eMMC做通訊(起始會先喚醒)\n",
        "\n",
        "\n",
        "```\n",
        "Command line: 48 bits\n",
        "\n",
        "Usage: start transmission command_idx Args(address)  CRC    end\n",
        "bit:   0b    1b     6 bits   32 bits    6 bits   1b\n",
        "\n",
        "\n",
        "Response line: 48 or 136 bits\n",
        "\n",
        "Case 1.: alike command line, but 'transmission' is 0b\n",
        "\n",
        "Case 2.:\n",
        "Usage: start trans.. check_bits  CSD/CID_regi_val  end  \n",
        "bit:   0b   0b   111111b    127 bits     1b\n",
        "\n",
        "Case 3.:\n",
        "Usage: start trans.. check_bits  OCR_regi_val  check_bits  end  \n",
        "bit:   0b   0b   111111b    32 bits    111111b   1b\n",
        "\n",
        "Case 4.:\n",
        "Usage: start trans.. check_bits  RCA    status  register_addr. content  CRC   end\n",
        "bit:   0b   0b   100111b   16 bits  1b    7 bits    8 bits  7 bits  1b\n",
        "\n",
        "Case 5.(request 4 stop mode):\n",
        "Usage: start trans.. CMD40    RCA    not_def     CRC   end\n",
        "bit:   0b   0b  101000b  16 bits  16 bits    7 bits  1b\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "88doy6L-kP3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Data block transfer\n",
        "\n",
        "可以選擇要DDR(dual data rate)或SDR, 也就是雙/單端觸發。其 high speed mode下則分別為 HS400/ HS200。另外也有 4 or 8 bits傳輸可選擇。\n",
        "\n",
        "```\n",
        "其實格式相同,只是一個有雙端觸發\n",
        "\n",
        "DDR8:\n",
        "        start              CRC        end\n",
        "       (2 bits)  LSB   MSB   (只看上緣)   (2 bits)\n",
        "*   DAT7:  0b x   b7 ... b7    16 bits    1b  x\n",
        "*   ...    ...    .    .     ...       ...\n",
        "*   DAT0:  0b x   b0 ... b0     ...      1b  x\n",
        "\n",
        "DDR4: 類似\n",
        "        start                  CRC      end\n",
        "       (2 bits)  LSB      MSB    (只看上緣)   (2 bits)\n",
        "*   DAT3:  0b x   b7 b3 ... b7 b3    16 bits    1b  x\n",
        "*   ...    ...    .       .       ...      ...\n",
        "*   DAT0:  0b x   b4 b0 ... b0 b0      ...     1b  x\n",
        "\n",
        "\n",
        "\n",
        "SDR8:                              \n",
        "       start   LSB   MSB    CRC      end\n",
        "*   DAT7:  0b   b7 ... b7    16 bits    1b  \n",
        "*   ...   ...   .    .     ...      ...\n",
        "*   DAT0:  0b   b0 ... b0     ...      1b\n",
        "\n",
        "SDR4\n",
        "       start   LSB     MSB    CRC      end\n",
        "*   DAT3:  0b   b7 b3 ... b7 b3   16 bits   1b  \n",
        "*   ...    ...   .      .     ...     ...\n",
        "*   DAT0:  0b   b4 b0 ... b0 b0    ...     1b\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v-XgDCecIwZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main code"
      ],
      "metadata": {
        "id": "KwL7lJRYrbvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Suggestion\n",
        "A better logic analyzer (higher sampling rate and fine software) can greatly help your work."
      ],
      "metadata": {
        "id": "Yoj6U_uqoTJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import"
      ],
      "metadata": {
        "id": "9iK_ICKHGzuL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zivnF8AJ9WjH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import pandas as pd\n",
        "# deque適合只操作首末元素時用"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_byte(bin_data):\n",
        "    \"\"\"\n",
        "    Convert binary data to hexadecimal format.(不成8的末位會補0)\n",
        "    ['0','0'...] or ['0...',..] --> ['0x??',..] -> ['??',..]\n",
        "    \"\"\"\n",
        "    bin_str = ''.join(list(bin_data))\n",
        "    bits_list = [bin_str[i:i+8].ljust(8, '0') for i in range(0, len(bin_str), 8)]\n",
        "    return [hex(int(bits, 2))[2:].zfill(2) for bits in bits_list]\n",
        "\n",
        "\n",
        "def convert_to_binary(row_data, pkt_len=None, mode=None):\n",
        "    \"\"\"\n",
        "    Convert data to binary form\n",
        "    mode = input type: 'SPI', 'BIN'. Turn hex to binary if not given\n",
        "\n",
        "    \"\"\"\n",
        "    if mode == 'SPI':\n",
        "        # decimal: ['1',... -> [0b1,..-> ['00000001',...], MSB first\n",
        "        int_data = [int(number) for number in row_data if number]\n",
        "        return [bin(num)[2:].zfill(8) for num in int_data]\n",
        "\n",
        "    elif mode == 'BIN' and row_data in ['3', '2']:\n",
        "        # Extract numbers(len). Returns re.Match object if found, else None.\n",
        "        search = re.match(r'(\\d+)', pkt_len) if pkt_len else ValueError('pkt_len is not given')\n",
        "        # Filter noise.\n",
        "        if search:\n",
        "            pkt_length = int(search.group(1))\n",
        "            return generate_bit(row_data) if pkt_length >= 200 else None\n",
        "\n",
        "    else:\n",
        "        # ['0a',..] -> ['0000...',...] -> ['0','0',...]\n",
        "        int_data = [int(hex_num, 16) for hex_num in row_data if pd.notna(hex_num)]\n",
        "        binary_list = [bin(num)[2:].zfill(8) for num in int_data]\n",
        "        return [char for binary_string in binary_list for char in binary_string]"
      ],
      "metadata": {
        "id": "RQlZAvo6z8dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Current logic analyzer\n",
        "DSLogic輸出格式為 .csv: (id, time, data).  \n",
        "抽取指定bit並轉換為bytes，最後輸出成 .xlsx/.csv"
      ],
      "metadata": {
        "id": "jO8xfTEhwkuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        csv_reader = csv.reader(file, delimiter=',')\n",
        "        next(csv_reader)  # Skip header\n",
        "        return [\n",
        "            str(row[2].strip()) for row in csv_reader\n",
        "            if len(row) >= 3\n",
        "        ]\n",
        "\n",
        "def read_all_csv_files(folder_path):\n",
        "    all_datas = []\n",
        "\n",
        "    # 由編號大小逐一讀取\n",
        "    def natural_sort(file_name):\n",
        "        return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', file_name)]\n",
        "\n",
        "    for file_name in sorted(os.listdir(folder_path), key=natural_sort):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            datas = read_csv(file_path)\n",
        "            all_datas.extend(datas)\n",
        "    return all_datas\n",
        "\n",
        "\n",
        "def generate_mask(mask_length, ranges=None):\n",
        "    \"\"\"Generate a binary mask with specified ranges.\n",
        "    ex. (41,  None or [(0, 5), ......]) to [0,0,1,...]\"\"\"\n",
        "    if ranges is None:\n",
        "        return [1] * mask_length\n",
        "\n",
        "    mask = [0] * mask_length\n",
        "    for start, end in ranges:\n",
        "        mask[start:min(end, mask_length)] = [1] * (min(end, mask_length) - start)\n",
        "\n",
        "    return mask\n",
        "\n",
        "def apply_mask(data, mask):\n",
        "    \"\"\"Extract data based on mask.\"\"\"\n",
        "    return [d for d, m in zip(data, mask) if m]\n",
        "\n",
        "def data_extraction(data, mask):\n",
        "    \"\"\"Extract and reshape data.\"\"\"\n",
        "    flat_data = [item for sublist in data for item in sublist] if isinstance(data[0], list) else data\n",
        "\n",
        "    extracted_data = []\n",
        "    mask_length = len(mask)\n",
        "\n",
        "    for i in range(0, len(flat_data), mask_length):\n",
        "        segment_data = flat_data[i:i + mask_length]\n",
        "\n",
        "        # 去除長度不滿的殘餘訊號\n",
        "        if len(segment_data) != mask_length:\n",
        "            break\n",
        "\n",
        "        # Extract the data\n",
        "        extracted_segment = apply_mask(segment_data, mask)\n",
        "        extracted_data.append(extracted_segment)\n",
        "\n",
        "    return extracted_data"
      ],
      "metadata": {
        "id": "3DPUzLNtdJWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Command sorting functions\n",
        "def bin_data_processor(bin_data_lists, target_str=None, target_cmd=None, output_file=None, big_endian=True, drop_duplicates=False):\n",
        "    \"\"\"\n",
        "    Processes binary data and filters it based on target patterns.\n",
        "    Outputs the result as a CSV or Excel file.\n",
        "\n",
        "    Parameters:\n",
        "    - bin_data_lists: List of binary data strings to process.\n",
        "    - target_str: String to filter binary data (optional).\n",
        "    - target_cmd: Command prefix to filter binary data (optional).\n",
        "    - output_file: File path for the output data (CSV or Excel).\n",
        "    - big_endian: Boolean, determines the byte order (default is True).\n",
        "    - drop_duplicates: Boolean, removes duplicate entries if True.\n",
        "    \"\"\"\n",
        "    byte_datas = []\n",
        "\n",
        "    for bin_data in bin_data_lists:\n",
        "        # Join binary data based on byte order\n",
        "        bin_str = ''.join(bin_data) if big_endian else ''.join(reversed(bin_data))\n",
        "        should_process = True\n",
        "\n",
        "        # Filter by target string if provided\n",
        "        if target_str and bin_str.find(target_str) == -1:\n",
        "            should_process = False\n",
        "\n",
        "        # Filter by target command and process remaining data\n",
        "        if target_cmd and should_process:\n",
        "            if bin_str.startswith(target_cmd):\n",
        "                remaining_part = bin_str[len(target_cmd):]\n",
        "                output_str = to_byte(target_cmd) + to_byte(remaining_part)\n",
        "                byte_datas.append(output_str)\n",
        "                continue\n",
        "            else:\n",
        "                should_process = False\n",
        "\n",
        "        # Add the entire binary string if it passes all filters\n",
        "        if should_process:\n",
        "            output_str = to_byte(bin_str)\n",
        "            byte_datas.append(output_str)\n",
        "\n",
        "    # Create DataFrame and optionally drop duplicates\n",
        "    df = pd.DataFrame(byte_datas)\n",
        "    print(byte_datas[:5])\n",
        "    if drop_duplicates:\n",
        "        df = df.drop_duplicates(keep=False)\n",
        "        print(f\"Duplicates removed. Remaining entries: {len(df)}\")\n",
        "\n",
        "    # Save the processed data to the specified file format\n",
        "    if output_file.endswith('.csv'):\n",
        "        df.to_csv(output_file, index=False, header=False)\n",
        "    else:\n",
        "        df.to_excel(output_file, index=False, header=False)\n",
        "\n",
        "\n",
        "def process_binary_data(input_folder, output_file, target_str=None, target_cmd=None, drop_duplicates=True):\n",
        "    \"\"\"\n",
        "    Reads binary data, then resize and applies a mask to extract it.\n",
        "\n",
        "    Parameters:\n",
        "    - input_folder: Path to the folder containing input CSV files.\n",
        "    - output_file: Path to save the processed output file.\n",
        "    - target_str: Binary string (optional).\n",
        "    - target_cmd: Binary command prefix (optional).\n",
        "    - drop_duplicates: Boolean, removes exact same line if True.\n",
        "    \"\"\"\n",
        "    # Generate a binary mask for filtering\n",
        "    # For this project, every line is 41 bits, include 5 bits + stop/start bit + 34 bits + stop bit.\n",
        "    # With specific hypothesis, shall you extract 1 or more times to assemble the desired result.\n",
        "    # e.g. (41,  None or [(0, 5)] or [(6, 40)] or [(8, 40)] or [(6, 14), (15, 23), (24, 32)] or [(0, 5), [(8, 40)] with target_cmd ...)\n",
        "    data_mask = generate_mask(41, [(0, 5)])\n",
        "\n",
        "    datas = read_all_csv_files(input_folder)  # Load data from CSV files\n",
        "    bin_data_lists = data_extraction(datas, data_mask)  # Define bit length per signal and extract it\n",
        "\n",
        "    return bin_data_processor(\n",
        "        bin_data_lists,\n",
        "        target_str=target_str,\n",
        "        target_cmd=target_cmd,\n",
        "        output_file=output_file,\n",
        "        drop_duplicates=drop_duplicates,\n",
        "    )"
      ],
      "metadata": {
        "id": "hjFfhAQoi3b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = '.'\n",
        "output_file = '4_validaton_unique_col.csv'  #  can be .csv or .xlsx\n",
        "target_str = '0000000000000000'\n",
        "target_cmd = '10011'  # 補0後為0x98\n",
        "\n",
        "process_binary_data(input_folder=input_folder, output_file=output_file, drop_duplicates=False, target_cmd=None) #, target_str=target_str)"
      ],
      "metadata": {
        "id": "xr-tdjgk-eIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bca107a-0894-4ef3-d727-ac11758fa5cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['b0'], ['b8']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_hex_data(input_folder, output_file, target_str=None, target_cmd=None):\n",
        "    \"\"\"\n",
        "    Reads hex data, applies a mask, and processes it.\n",
        "    \"\"\"\n",
        "    data_mask = generate_mask(8, [(0, 5)])  # pattern to extract specific bit\n",
        "\n",
        "    datas = read_all_csv_files(input_folder)  # Load data from CSV files\n",
        "    hex_data_lists = data_extraction(datas, data_mask)\n",
        "    bin_data_lists = [convert_to_binary(hex_data) for hex_data in hex_data_lists]\n",
        "    return bin_data_processor(\n",
        "        bin_data_lists,\n",
        "        target_str=target_str,\n",
        "        target_cmd=target_cmd,\n",
        "        output_file=output_file,\n",
        "    )"
      ],
      "metadata": {
        "id": "1uoidtaeyuri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = './input'\n",
        "output_file = 'test.xlsx'  #  .csv or .xlsx\n",
        "\n",
        "process_hex_data(input_folder=input_folder, output_file=output_file)"
      ],
      "metadata": {
        "id": "2s44TI1QJQFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Previous logic analyzer - 1\n",
        "輸出格式為 (time, scl, sda). Wanna let csv to .xlsx/.csv"
      ],
      "metadata": {
        "id": "Ce6vGFf1wIxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        csv_reader = csv.reader(file, delimiter=',')\n",
        "        next(csv_reader)  # 跳過標題行\n",
        "        next(csv_reader)  # 跳過0s\n",
        "        return [\n",
        "                (float(row[0].strip()), row[2].strip(), row[1].strip())\n",
        "                for row in csv_reader\n",
        "                if len(row) >= 3 and row[2].strip().isdigit() and row[1].strip().isdigit()\n",
        "            ]\n",
        "\n",
        "def read_all_csv_files(folder_path):\n",
        "    all_datas = []\n",
        "    for file_name in sorted(os.listdir(folder_path)):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            datas = read_csv(file_path)\n",
        "            all_datas.extend(datas)   # 將元素加到末尾(不含[])\n",
        "    return all_datas\n",
        "\n",
        "\n",
        "# CSV to protocol form\n",
        "def process_data(datas):\n",
        "    bin_datas = []\n",
        "    pre_scl = None\n",
        "    prev_time = 0\n",
        "    worksheet = []\n",
        "\n",
        "    for (time, scl, sda) in datas:\n",
        "        if scl == '1' and time - prev_time >= 0.0000007 and pre_scl != '1':\n",
        "            # 一旦有值更改就會被輸出，因此以週期作區分且設為正緣觸發\n",
        "            if time - prev_time > 0.005:\n",
        "                # 長於5ms則視為不同輸入\n",
        "                bin_str = ''.join(bin_datas)\n",
        "                byte_data = extract_binary_row_data(bin_str, 'analyze_protocol', (41,[0,5,40]))\n",
        "                worksheet.extend(byte_data)\n",
        "                bin_datas = []  # 清空 bin_datas\n",
        "            bin_datas.extend(sda)\n",
        "            prev_time = time\n",
        "\n",
        "        pre_scl = scl  # 使中央stop-start影響降至1 bit\n",
        "\n",
        "\n",
        "\n",
        "    bin_str = ''.join(bin_datas)\n",
        "    byte_data = extract_binary_row_data(bin_str, 'analyze_protocol', (41,[0,5,40]))\n",
        "    worksheet.extend(byte_data)\n",
        "    workbook = pd.DataFrame(worksheet)\n",
        "    workbook.to_excel('老三258_test.xlsx', index=False, header=False)\n",
        "\n",
        "\n",
        "\n",
        "input_folder ='.'\n",
        "\n",
        "process_data(read_all_csv_files(input_folder))"
      ],
      "metadata": {
        "id": "pILdD4QXJAQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  臨時直接以首行做分類用\n",
        "def seperate_from_firstline(input_folder, output_file):\n",
        "  \"\"\"\n",
        "  Extract row data from an input Excel file to an output Excel file.\n",
        "  \"\"\"\n",
        "  for filename in os.listdir(input_folder):\n",
        "      if filename.endswith(\".xlsx\"):\n",
        "          file_path = os.path.join(input_folder, filename)\n",
        "          print(\"Opening file:\", file_path)\n",
        "\n",
        "          df = pd.read_excel(file_path, header=None, dtype=str)\n",
        "\n",
        "          extracted_hex_data =[]\n",
        "          for _, row in df.iterrows():\n",
        "              if row[0] not in ['0111', '0011', '0110']:   # 'ee'...etc\n",
        "                    extracted_hex_data.append([data for data in row if data])\n",
        "\n",
        "\n",
        "          # Create a new DataFrame with the extracted data\n",
        "          df_extracted = pd.DataFrame(extracted_hex_data)\n",
        "\n",
        "          # Save the new DataFrame to an Excel file\n",
        "          df_extracted.to_excel(output_file, index=False, header=False)\n",
        "\n",
        "\n",
        "seperate_from_firstline(input_folder=input_folder,\n",
        "                  output_file='277_else.xlsx',\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AXSMp2vwPaH",
        "outputId": "98eaa3dc-134b-421d-e3a5-47ca8caad87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening file: ./老三277_test.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Previous logic analyzer - 2"
      ],
      "metadata": {
        "id": "4XsrZTlhxvvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSVs 2 excel"
      ],
      "metadata": {
        "id": "jY44QYNOzqLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl\n",
        "\n",
        "def read_csv(file_path, mode):\n",
        "    with open(file_path, 'r') as file:\n",
        "        csv_reader = csv.reader(file, delimiter=',')\n",
        "        next(csv_reader)  # 跳過標題行\n",
        "        if mode == 'SPI':\n",
        "            # 取出偶數行中的Decimal data，並去除空字符串或無效的數字字符串\n",
        "            return [\n",
        "                ([x for x in row[3:] if x.strip() and x.strip().isdigit()], None)\n",
        "                for row_idx, row in enumerate(csv_reader)\n",
        "                if row_idx % 2 == 0\n",
        "            ]\n",
        "        elif mode == 'BIN':\n",
        "            # 提取Data, pkt_len，並去除空字符串或無效的數字字符串\n",
        "            return [\n",
        "                (row[3].strip(), row[4].strip())\n",
        "                for row in csv_reader\n",
        "                if row[3].strip().isdigit() and row[4].strip().isdigit()\n",
        "            ]\n",
        "\n",
        "\n",
        "def read_all_csv_files(folder_path, mode):\n",
        "    all_datas = []\n",
        "    for file_name in sorted(os.listdir(folder_path)):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            datas = read_csv(file_path, mode)\n",
        "            all_datas.extend(datas)   # 將元素加到末尾(不含[])\n",
        "    return all_datas\n",
        "\n",
        "\n",
        "def sequence_to_set(sequences):\n",
        "    if sequences is None:\n",
        "        return None, None\n",
        "\n",
        "    # 資料與長度各設為一個set\n",
        "    length_set = {len(seq) for seq in sequences}\n",
        "    sequence_set = set(sequences)\n",
        "\n",
        "    return sequence_set,  length_set\n",
        "\n",
        "\n",
        "def generate_bit(Data):\n",
        "    # 資料判讀\n",
        "    if Data == '3':\n",
        "        return '1'\n",
        "    elif Data == '2':\n",
        "        return '0'\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def matching(sub_q, data_set, len_set, worksheet):\n",
        "    \"\"\"\n",
        "    Match subsequence with data set.\n",
        "\n",
        "    Args:\n",
        "        sub_q (list): The subsequence to match.\n",
        "        data_set (set): The set to compare with.\n",
        "        len_set (list): List of lengths to check for matching.\n",
        "        worksheet (list): List to append matched sequences.\n",
        "        bin_list (list): List to append binary sequences.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    if data_set is None:\n",
        "        raise ValueError('Sequence is not given')\n",
        "\n",
        "    elif len(sub_q) >= min(len_set):\n",
        "        for length in len_set:\n",
        "            sub_seq = ''.join(sub_q[-length:])\n",
        "            if sub_seq in data_set:\n",
        "                data_q = sub_q[:-length]\n",
        "                worksheet.append(to_byte(data_q))\n",
        "                sub_q.clear()\n",
        "\n",
        "\n",
        "def process_data(datas, mode, start_end_seq=None):\n",
        "    sub_queue = []\n",
        "\n",
        "    # 以set查找\n",
        "    seq_set, seq_len = sequence_to_set(start_end_seq)\n",
        "\n",
        "    # 啟用Excel\n",
        "    workbook = openpyxl.Workbook()\n",
        "    worksheet = workbook.active\n",
        "\n",
        "    if start_end_seq:\n",
        "        for data, pkt_len in datas:\n",
        "            bin_datas = convert_to_binary(data, pkt_len, mode)\n",
        "            for data in bin_datas:\n",
        "                sub_queue.extend(data)\n",
        "                matching(sub_queue,\n",
        "                         seq_set,\n",
        "                         seq_len,\n",
        "                         worksheet)\n",
        "            sub_queue.clear()\n",
        "\n",
        "    else:\n",
        "        if mode=='SPI':\n",
        "            for data, pkt_len in datas:\n",
        "                # SPI下的data為一list   有誤\n",
        "                hex_datas = [\n",
        "                    hex(int(dec_data.strip()))[2:].zfill(2)\n",
        "                    for dec_data in data\n",
        "                ]\n",
        "                worksheet.append(hex_datas)\n",
        "        elif mode=='BIN':\n",
        "            for data, pkt_len in datas:\n",
        "                bin_datas = convert_to_binary(data, pkt_len, mode)\n",
        "                worksheet.append(to_byte(bin_datas))\n",
        "        else:\n",
        "            raise ValueError('Invalid mode')\n",
        "\n",
        "\n",
        "    # 儲存 Excel, 注意不成行序列\n",
        "    workbook.save('output.xlsx')"
      ],
      "metadata": {
        "id": "xgMFHuXQEiS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 讀取CSV,輸出excel\n",
        "input_folder = '.'\n",
        "data = read_all_csv_files(input_folder, 'SPI')\n",
        "process_data(datas=data, mode='SPI')"
      ],
      "metadata": {
        "id": "-FbA886hEiXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Excel extraction\n",
        "自 hex data篩出特定的 bits組出byte"
      ],
      "metadata": {
        "id": "-kncf7Z8zlGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def num_unique_values(col):\n",
        "    \"\"\"\n",
        "    Returns the number of unique non-space values in a pd.Series or DataFrame column.\n",
        "    \"\"\"\n",
        "    return col.nunique(axis=1)\n",
        "\n",
        "\n",
        "def extract_binary_row_data(row_data, filter=None, param=None):\n",
        "    \"\"\"\n",
        "    Extract desired sequences from binary row data based on different filters and parameters.\n",
        "\n",
        "    Parameters:\n",
        "    row_data (list): List of binary data to be processed.\n",
        "    filter (str, optional): The type of filter to apply ('target_str', 'excess_bits', 'analyze_protocol'). Default is None.\n",
        "    param (optional): Parameter for the chosen filter. If filter is 'target_str', it should be a string.\n",
        "                      If filter is 'excess_bits' or 'analyze_protocol', it should be a tuple (length of sequence, [undesired bit positions in the sequence]).\n",
        "\n",
        "    Returns:\n",
        "    list: A list of processed data according to the specified filter and parameter.\n",
        "    \"\"\"\n",
        "    # concate pd.series to a str\n",
        "    valid_data = [str(data) for data in row_data if data]\n",
        "    data_str = ''.join(valid_data)\n",
        "\n",
        "    if filter is None:\n",
        "        return [to_byte(data_str)]\n",
        "\n",
        "    elif param is None:\n",
        "        raise ValueError('param is not given')\n",
        "\n",
        "    elif filter == 'target_str':\n",
        "        # 以開頭做區分\n",
        "        #if data_str.startswith(param):\n",
        "        #   return [to_byte(data_str)]\n",
        "        # 找特定行\n",
        "        return [to_byte(data_str)] if param in data_str else None\n",
        "        # 只輸出指定序列後的資料\n",
        "        #pattern = re.compile(f'{param}(.*?)(?={param}|$)')\n",
        "        #data_list = pattern.findall(data_str)  # 削去指定序列後留下'',沒找到會=[]\n",
        "        #return [to_byte(data) for data in data_list if data]\n",
        "\n",
        "    elif filter == 'excess_bits':\n",
        "        # 去除多餘的bits,不影響排序\n",
        "        length, remove_positions = param\n",
        "        data_chunks = [data_str[i:i+length] for i in range(0, len(data_str), length)]\n",
        "        filtered_chunks = [\n",
        "            ''.join(char for i, char in enumerate(chunk) if i not in remove_positions)\n",
        "            for chunk in data_chunks\n",
        "        ]\n",
        "        return [to_byte(''.join(filtered_chunks))]\n",
        "\n",
        "    elif filter == 'analyze_protocol':\n",
        "        # 去除多餘的bits, 按照指定長度排序\n",
        "        length, remove_positions = param\n",
        "        data_chunks = [data_str[i:i+length] for i in range(0, len(data_str), length)]\n",
        "        filtered_chunks = [\n",
        "            ''.join(char for i, char in enumerate(chunk) if i not in remove_positions)\n",
        "            for chunk in data_chunks\n",
        "        ]\n",
        "        return [[filtered_str[:4]] + to_byte(filtered_str[4:]) for filtered_str in filtered_chunks]\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise ValueError('Invalid filter')\n",
        "\n",
        "\n",
        "\n",
        "def extract_from_xlsx(input_folder, output_file, mode=None, filter=None, param=None):\n",
        "  \"\"\"\n",
        "  Extract row data from an input Excel file to an output Excel file.\n",
        "  \"\"\"\n",
        "  for filename in sorted(os.listdir(input_folder)):\n",
        "      if filename.endswith(\".xlsx\"):\n",
        "          file_path = os.path.join(input_folder, filename)\n",
        "          print(\"Opening file:\", file_path)\n",
        "\n",
        "          # Read the Excel file into a DataFrame with binary form\n",
        "          df = pd.read_excel(file_path, header=None, dtype=str)\n",
        "          df = pd.DataFrame(convert_to_binary(row) for _, row in df.iterrows())\n",
        "\n",
        "          # clear same data if needed\n",
        "          if mode == 'clear_same_column':\n",
        "              unique_counts = df.nunique()\n",
        "              cols_to_keep = unique_counts[unique_counts > 1].index\n",
        "              df = df[cols_to_keep]\n",
        "              df.columns = range(df.shape[1])\n",
        "\n",
        "          # Extract binary data from each row\n",
        "          extracted_hex_data =[]\n",
        "          for _, row in df.iterrows():\n",
        "              extracted_bin_data = extract_binary_row_data(row, filter, param)\n",
        "              # print(extracted_bin_data) if extracted_bin_data else None\n",
        "              extracted_hex_data.extend(extracted_bin_data) if extracted_bin_data else None\n",
        "\n",
        "\n",
        "          # Create a new DataFrame with the extracted data\n",
        "          df_extracted = pd.DataFrame(extracted_hex_data)\n",
        "\n",
        "          # Save the new DataFrame to an Excel file\n",
        "          df_extracted.to_excel(output_file, index=False, header=False)\n"
      ],
      "metadata": {
        "id": "IuqpqCCHfNXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 要去除的binary通訊協定之stop-start\n",
        "excess_position = (41,[0,5,40])\n",
        "\n",
        "# 目標序列，篩出之後的資料\n",
        "target_sequence = '0000000000000000'\n",
        "\n",
        "# 指定檔案位置，初始為當下位置\n",
        "input_folder = '.'"
      ],
      "metadata": {
        "id": "BgQHpHrpRtUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 篩出excel資料\n",
        "extract_from_xlsx(input_folder=input_folder,\n",
        "                  output_file='258_0000.xlsx',\n",
        "                  #mode='clear_same_column',\n",
        "                  filter='target_str',\n",
        "                  param=target_sequence\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hRjABbS-A-4",
        "outputId": "f0012305-928f-4aa1-9a28-fe2b2451f572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening file: ./258pure.xlsx\n"
          ]
        }
      ]
    }
  ]
}
